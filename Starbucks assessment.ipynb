{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Exercise: Starbucks\n",
    "<br>\n",
    "\n",
    "<img src=\"https://opj.ca/wp-content/uploads/2018/02/New-Starbucks-Logo-1200x969.jpg\" width=\"200\" height=\"200\">\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "#### Background Information\n",
    "\n",
    "The dataset was originally used as a take-home assignment provided by Starbucks for their job candidates. The data for this exercise consists of about 120,000 data points split in a 2:1 ratio among training and test files. In the experiment simulated by the data, an advertising promotion was tested to see if it would bring more customers to purchase a specific product priced at $10. Since it costs the company 0.15 to send out each promotion, it would be best to limit that promotion only to those that are most receptive to the promotion. Each data point includes one column indicating whether or not an individual was sent a promotion for the product, and one column indicating whether or not that individual eventually purchased that product. Each individual also has seven additional features associated with them, which are provided abstractly as V1-V7.\n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "The goal in this notebook is to use the training data to understand what patterns in V1-V7 to indicate that a promotion should be provided to a user. Specifically, the goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "IRR depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion. Mathematically, it's the ratio of the number of purchasers in the promotion group to the total number of customers in the purchasers group (_treatment_) minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group (_control_).\n",
    "\n",
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$\n",
    "\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "NIR depicts how much is made (or lost) by sending out the promotion. Mathematically, this is 10 times the total number of purchasers that received the promotion minus 0.15 times the number of promotions sent out, minus 10 times the number of purchasers who were not given the promotion.\n",
    "\n",
    "$$ NIR = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl}$$\n",
    "\n",
    "For a full description of what Starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "Below you can find the training data provided.  We explore the data and different optimization strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044332</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044332 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# load in the data\n",
    "train_data = pd.read_csv('./training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection and Distribution of Promotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a quick check of the dtypes, shape, missing and unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "Promotion     object\n",
       "purchase       int64\n",
       "V1             int64\n",
       "V2           float64\n",
       "V3           float64\n",
       "V4             int64\n",
       "V5             int64\n",
       "V6             int64\n",
       "V7             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           84534\n",
       "Promotion        2\n",
       "purchase         2\n",
       "V1               4\n",
       "V2           84518\n",
       "V3              40\n",
       "V4               2\n",
       "V5               4\n",
       "V6               4\n",
       "V7               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cells for you to work and document as necessary - \n",
    "# definitely feel free to add more cells as you need\n",
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84534, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Promotion    0\n",
       "purchase     0\n",
       "V1           0\n",
       "V2           0\n",
       "V3           0\n",
       "V4           0\n",
       "V5           0\n",
       "V6           0\n",
       "V7           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find if this offer had an incremental response, we first check the distribution of the the promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>0</th>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "      <td>41851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>0</th>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "      <td>41643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID     V1     V2     V3     V4     V5     V6     V7\n",
       "Promotion purchase                                                        \n",
       "No        0         41851  41851  41851  41851  41851  41851  41851  41851\n",
       "          1           319    319    319    319    319    319    319    319\n",
       "Yes       0         41643  41643  41643  41643  41643  41643  41643  41643\n",
       "          1           721    721    721    721    721    721    721    721"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prom_count = train_data.groupby(['Promotion', 'purchase']).count()\n",
    "prom_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate IRR and NIR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that the observed Incremental Response Rate and Net Incremental Revenue are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$NIR   = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "purch_treat = prom_count.iloc[3][3]\n",
    "cust_treat = purch_treat + prom_count.iloc[2][3]\n",
    "purch_ctrl = prom_count.iloc[1][3]\n",
    "cust_ctrl = purch_ctrl + prom_count.iloc[0][3]\n",
    "\n",
    "#the observeed irr is..\n",
    "obs_irr = purch_treat/cust_treat  - purch_ctrl/cust_ctrl\n",
    "#the observed nir is..\n",
    "obs_nir = (10*purch_treat - 0.15*cust_treat) - 10*purch_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009454547819772702, -2334.5999999999995)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_irr, obs_nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bootstrap this sample to simulate the sampling distribution of the IRR and NIR.  Here we will take 20 percent of the whole data = (16907) for the sub-sample size for bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16906.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0]*.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_sim=[]\n",
    "nir_sim=[]\n",
    "for _ in range(10000):\n",
    "    b_samp = train_data.sample(16907, replace = True)\n",
    "    prom_count_sim = b_samp.groupby(['Promotion', 'purchase']).count()\n",
    "    purch_treat = prom_count_sim.iloc[3][3] \n",
    "    cust_treat = purch_treat + prom_count_sim.iloc[2][3]\n",
    "    purch_ctrl = prom_count_sim.iloc[1][3]\n",
    "    cust_ctrl = purch_ctrl + prom_count_sim.iloc[0][3]\n",
    "    irr = purch_treat/cust_treat  - purch_ctrl/cust_ctrl\n",
    "    nir = (10*purch_treat - 0.15*cust_treat) - 10*purch_ctrl\n",
    "    irr_sim.append(irr)\n",
    "    nir_sim.append(nir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute the p-value for our statistic, the irr and nir, by simulating the distribution under the null hypothesis and then finding the probability that our statistic came from that distribution. To simulate the null, we'll create a normal distribution centered at zero, with the same standard devation and size as our simulated sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_vals_irr = np.random.normal(sum(irr_sim)/16907, np.array(irr_sim).std(), np.array(irr_sim).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(null_vals_irr, bins =60)\n",
    "plt.axvline(obs_irr*16907/train_data.shape[0], color = 'red')\n",
    "plt.title(\"Normal Distribution under the Null Hypothesis\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value for the irr is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0136"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val_IRR = (obs_irr * .2 > null_vals_irr).mean()\n",
    "p_val_IRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the corresponding null hypothesis for the nir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_vals_nir = np.random.normal(sum(nir_sim)/16907, np.array(nir_sim).std(), np.array(nir_sim).size)\n",
    "plt.hist(null_vals_nir, bins=60)\n",
    "plt.axvline(obs_nir *  16907/train_data.shape[0], color = 'red')\n",
    "plt.title(\"Normal Distribution under the Null Hypothesis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val_NIR = (obs_nir *.2 > null_vals_nir).mean()\n",
    "p_val_NIR <0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed values of $IRR$ is statistically significant based on the $p$-value of 0.0139 and an $\\alpha$ of 0.025 (adopting the Bonferroni Correction). The observed value of $NIR$ does not appear to be statistically significant based on the $p$-value computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments results analysis\n",
    "\n",
    "The incremental response rate observed in the data shows that the promotion had a statisically significant impact in increasing the number of customers who purchased the product. \n",
    "\n",
    "The observed net incremental revenue, however, is negative but not necessarily statistically significant. The advertising promotion is bringing more customers to purchase the product but given the promotion costs and the net revenue levels, it's possible to optimize the targeting of the promotion and maximize the $IRR$ and $NIR$.\n",
    "\n",
    "The following model will aims at selecting the best customers to target and maximize the Incremental Response Rate and Net Incremental Revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is unbalanced as there are fewer rows with labels corresponding to purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 83494)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.purchase == 1).sum(), (train_data.purchase == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do deal with this unbalanced data, we will train a model using a subset of the data set where both labels for the response variables are equally represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data_purchase_0 = train_data.loc[random.sample(set(train_data.purchase[train_data.purchase == 0].index), 1040)]\n",
    "data_purchase_1 = train_data.loc[random.sample(set(train_data.purchase[train_data.purchase == 1].index), 1040)]\n",
    "data_balanced = pd.concat([data_purchase_1, data_purchase_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the explanatory variables $X$ and response variable $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_balanced.drop(['ID', 'Promotion','purchase'], axis=1)\n",
    "y = data_balanced.purchase\n",
    "\n",
    "#Standarize features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']] = scaler.fit_transform(X[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a logistic regression model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# Create logistic regression object\n",
    "clf = LogisticRegression()\n",
    "# Train model\n",
    "LR_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542713567839196"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5662299854439592"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try a support vector machine classfier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5749636098981077\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "    y_pred = best_model.predict(df)\n",
    "    \n",
    "    promotion_yes_no = []\n",
    "    for value in y_pred:\n",
    "        if value == 0:\n",
    "            promotion_yes_no.append(\"No\")\n",
    "        if value == 1:\n",
    "            promotion_yes_no.append(\"Yes\")\n",
    "            \n",
    "    promotion = np.asarray(promotion_yes_no)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(promotion_strategy(X) == 'No').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0096.\n",
      "\n",
      "Your nir with this strategy is -1132.20.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009593158278250108, -1132.1999999999998)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'classifier': [LogisticRegression()],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(0, 4, 10)},\n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__n_estimators': [10, 100, 1000],\n",
    "                 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=166.81005372000593)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542713567839196"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
